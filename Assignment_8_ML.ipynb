{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed93e20",
   "metadata": {},
   "source": [
    "## 1. What exactly is a feature? Give an example to illustrate your point.\n",
    "\n",
    "        A feature is a column of the data,which directly or indirectly related to the output.Let's say for a housing price prediction problem,there are certain parameters that affect the price of a particular house like no of bedrooms,area sq, no of living rooms,etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b453479",
   "metadata": {},
   "source": [
    "## 2. What are the various circumstances in which feature construction is required?\n",
    "        \n",
    "         Feature construction aims to automatically transform the original representation space to a new one that can help better achieve data mining objectives,improved accuracy,easy comprehensibility,truthful clusters,revealing hidden patterns,etc \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881feb0d",
   "metadata": {},
   "source": [
    "## 3. Describe how nominal variables are encoded.\n",
    "\n",
    "        Nominal or categorical variables are rencoded using Scikit-Learn's OrdinalEncoder class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d4bd1",
   "metadata": {},
   "source": [
    "## 4. Describe how numeric features are converted to categorical features. \n",
    "\n",
    "        Let's say we have to grade students on the basis of their cumulative scores achieved in their tests,then students with marks between 91 and 100 are graded A,similarly,81 to 90 are graded B,and so and so.That is how we can convert numerical values(scores here) to categorical features(like A,B,C,etc)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519e62c",
   "metadata": {},
   "source": [
    "## 5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this approach?\n",
    "\n",
    "        In wrapper methods, the feature selection process is based on a specific machine learning algorithm that we are trying to fit on a given dataset.\n",
    "\n",
    "        It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion. The evaluation criterion is simply the performance measure which depends on the type of problem, for e.g. For regression evaluation criterion can be p-values, R-squared, Adjusted R-squared, similarly for classification the evaluation criterion can be accuracy, precision, recall, f1-score, etc. Finally, it selects the combination of features that gives the optimal results for the specified machine learning algorithm.\n",
    "        \n",
    "Advantage : Gives a better model\n",
    "\n",
    "Disavantage : Prone to overfitting\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c1718",
   "metadata": {},
   "source": [
    "## 6. When is a feature considered irrelevant? What can be said to quantify it?\n",
    "\n",
    "         Features are considered relevant if they are either strongly or weakly relevant, and are considered irrelevant otherwise.\n",
    "\n",
    "        Irrelevant features can never contribute to prediction accuracy, by definition. Also to quantify it we need to first check the list of features, There are three types of feature selection:\n",
    "\n",
    "        i. Wrapper methods (forward, backward, and stepwise selection)\n",
    "       ii. Filter methods (ANOVA, Pearson correlation, variance thresholding)\n",
    "      iii. Embedded methods (Lasso, Ridge, Decision Tree).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcd298b",
   "metadata": {},
   "source": [
    "## 7. When is a function considered redundant? What criteria are used to identify features that could be redundant?\n",
    "\n",
    "        When the correlation constant between two features is way too high,it is considered to be a redundant feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760c26d",
   "metadata": {},
   "source": [
    "## 8. What are the various distance measurements used to determine feature similarity?\n",
    "\n",
    "        Some of the most commonly used distance measures in machine learning are as follows:\n",
    "\n",
    "        i. Hamming Distance.\n",
    "       ii. Euclidean Distance\n",
    "      iii. Manhattan Distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663db55",
   "metadata": {},
   "source": [
    "## 9. State difference between Euclidean and Manhattan distances?\n",
    "\n",
    "        Euclidean distance is the shortest path between source and destination which is a straight line;manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec86004",
   "metadata": {},
   "source": [
    "## 10. Distinguish between feature transformation and feature selection.\n",
    "\n",
    "### Feature Transformation : \n",
    "        Feature transformation is a mathematical transformation in which we apply a mathematical formula to a particular column(feature) and transform the values which are useful for our further analysis. \n",
    "        \n",
    "### Feature Selection : \n",
    "        Selecting the most useful features and deleting the redundant ones "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf88fd",
   "metadata": {},
   "source": [
    "## 11. Make brief notes on any two of the following:\n",
    "\n",
    "### 2. Collection of features using a hybrid approach : \n",
    "\n",
    "        This can be achieved by Deep Hybrid Learning, which is the resultant fusion network, which can be achieved by combining Deep Learning and Machine Learning. In this article, we will learn how to use Deep Hybrid Learning, in which we will use Deep Learning methods to generate or extract features from unstructured data and use classical Machine Learning approaches to build highly accurate classification models using the unstructured data. Thus, using Deep Hybrid Learning (DHL) â€” we can take the benefits from both DL and ML and alleviate the drawbacks of both the techniques and provide more accurate and less computationally expensive solutions.\n",
    "        \n",
    "\n",
    "\n",
    "### 4. Receiver operating characteristic curve : \n",
    "        AUC - ROC curve is a performance measurement for the classification problems at various threshold settings. ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. Higher the AUC, the better the model is at predicting 0 classes as 0 and 1 classes as 1. By analogy, the Higher the AUC, the better the model is at distinguishing between patients with the disease and no disease.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
