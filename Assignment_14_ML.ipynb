{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22a204e",
   "metadata": {},
   "source": [
    "## 1. What is the concept of supervised learning? What is the significance of the name?\n",
    "\n",
    "        In Supervised learning the training set fed to the algorithm includes the desired solution.As the name signifies,supervised learning algorithms learn uder the supervision of both the training and the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe279f",
   "metadata": {},
   "source": [
    "## 2. In the hospital sector, offer an example of supervised learning.\n",
    "\n",
    "        There are multiple examples of supervised learning techniques being used the healthcare domain,like brain signal analysis,managing medical data,genome sequencing,cancer cell classification,etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11fe68b",
   "metadata": {},
   "source": [
    "## 3. Give three supervised learning examples.\n",
    "\n",
    "        i. KNN\n",
    "       ii. SVM\n",
    "      iii. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6612f",
   "metadata": {},
   "source": [
    "## 4. In supervised learning, what are classification and regression?\n",
    "\n",
    "        In classification,the algorithm is tasked with classifying the object like spam or no spam,hamdwriting letters clasification,etc.\n",
    "        \n",
    "        Regression algorithms are used for predicting numerical values, e.g. housing price prediction given a set of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adabd1bb",
   "metadata": {},
   "source": [
    "## 5. Give some popular classification algorithms as examples.\n",
    "\n",
    "        i. SVM\n",
    "       ii. Linear Regression\n",
    "      iii. Logistic Regression\n",
    "       iv. KNN\n",
    "        v. Neural Network\n",
    "       vi. Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2ec39",
   "metadata": {},
   "source": [
    "## 6. Briefly describe the SVM model.\n",
    "\n",
    "        Support vector machine or SVM is a  powerful and veratile ML model used for performing linear or non linear classification,regression and even outlier detection.\n",
    "        \n",
    "        SVMs are particularly suited for small or medium sized datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb05e2",
   "metadata": {},
   "source": [
    "## 7. In SVM, what is the cost of misclassification?\n",
    "\n",
    "        In cost-sensitive learning instead of each instance being either correctly or incorrectly classified, each class (or instance) is given a misclassification cost. Thus, instead of trying to optimize the accuracy, the problem is then to minimize the total misclassification cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffb696",
   "metadata": {},
   "source": [
    "## 8. In the SVM model, define Support Vectors.\n",
    "\n",
    "        Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25fd7d3",
   "metadata": {},
   "source": [
    "## 9. In the SVM model, define the kernel.\n",
    "\n",
    "        “Kernel” is used due to a set of mathematical functions used in Support Vector Machine providing the window to manipulate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d769755",
   "metadata": {},
   "source": [
    "## 10. What are the factors that influence SVM's effectiveness?\n",
    "\n",
    "        A) Selection of Kernel\n",
    "        B) Kernel Parameters\n",
    "        C) Soft Margin Parameter C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b153e89",
   "metadata": {},
   "source": [
    "## 11. What are the benefits of using the SVM model?\n",
    "\n",
    "        i. SVM works relatively well when there is a clear margin of separation between classes.\n",
    "        \n",
    "       ii. SVM is more effective in high dimensional spaces. \n",
    "       \n",
    "      iii. SVM is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "      \n",
    "      iv. SVM is relatively memory efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3e5a6",
   "metadata": {},
   "source": [
    "## 12.  What are the drawbacks of using the SVM model?\n",
    "\n",
    "        i. SVM algorithm is not suitable for large data sets.\n",
    "        \n",
    "       ii. SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
    "       \n",
    "      iii. In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform.\n",
    "      \n",
    "       iv. As the support vector classifier works by putting data points, above and below the classifying hyperplane there is no probabilistic explanation for the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b6149",
   "metadata": {},
   "source": [
    "## 13. Notes should be written on\n",
    "\n",
    "#### 1. The kNN algorithm has a validation flaw. \n",
    "\n",
    "        The relatively low accuracy of kNN is caused by several factors. One of them is that every characteristic of the method has the same result on calculating distance. The solution of this problem is to give weight to each data characteristic\n",
    "        \n",
    "#### 2. In the kNN algorithm, the k value is chosen.\n",
    "\n",
    "        The optimal K value usually found is the square root of N, where N is the total number of samples. Use an error plot or accuracy plot to find the most favorable K value. KNN performs well with multi-label classes, but you must be aware of the outliers.\n",
    "\n",
    "#### 3. A decision tree with inductive bias\n",
    "\n",
    "        Shorter trees are preferred over longer ones. Trees that place high information gain attributes close to the root are preferred over those that do not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c117a1d",
   "metadata": {},
   "source": [
    "## 14. What are some of the benefits of the kNN algorithm?\n",
    "\n",
    "        Some Advantages of KNN are:\n",
    "\n",
    "        i. Quick calculation time.\n",
    "       ii. Simple algorithm – to interpret.\n",
    "      iii. Versatile – useful for regression and classification.\n",
    "       iv. High accuracy – you do not need to compare with better-supervised learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6f22a",
   "metadata": {},
   "source": [
    "## 15. What are some of the kNN algorithm's drawbacks?\n",
    "\n",
    "        Some Disadvantages of KNN are:\n",
    "\n",
    "        i. Accuracy depends on the quality of the data.\n",
    "       ii. With large data, the prediction stage might be slow.\n",
    "      iii. Sensitive to the scale of the data and irrelevant features.\n",
    "       iv. Require high memory – need to store all of the training data.\n",
    "        v. Given that it stores all of the training, it can be computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512cb8d",
   "metadata": {},
   "source": [
    "## 16. Explain the decision tree algorithm in a few words.\n",
    "\n",
    "        A decision tree is a graphical representation of all the possible solutions to a decision based on certain conditions. Tree models where the target variable can take a finite set of values are called classification trees and target variable can take continuous values (numbers) are called regression trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347cd51a",
   "metadata": {},
   "source": [
    "## 17. What is the difference between a node and a leaf in a decision tree?\n",
    "\n",
    "        A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac445a5",
   "metadata": {},
   "source": [
    "## 18. What is a decision tree's entropy?\n",
    "\n",
    "        Entropy helps us to build an appropriate decision tree for selecting the best splitter. Entropy can be defined as a measure of the purity of the sub split. Entropy always lies between 0 to 1. The entropy of any split can be calculate by this formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d8625",
   "metadata": {},
   "source": [
    "## 19. In a decision tree, define knowledge gain.\n",
    "\n",
    "        Information gain is the reduction in entropy or surprise by transforming a dataset and is often used in training decision trees.Information gain is calculated by comparing the entropy of the dataset before and after a transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85217399",
   "metadata": {},
   "source": [
    "## 20. Choose three advantages of the decision tree approach and write them down.\n",
    "\n",
    "        Advantages of Decision Trees :\n",
    "\n",
    "        i. Easy to read and interpret. One of the advantages of decision trees is that their outputs are easy to read and interpret without requiring statistical knowledge.\n",
    "        \n",
    "       ii. Easy to prepare.\n",
    "       \n",
    "      iii. Less data cleaning required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb2160",
   "metadata": {},
   "source": [
    "## 21. Make a list of three flaws in the decision tree process.\n",
    "\n",
    "        Issues in Decision Tree Learning :\n",
    "\n",
    "        i. Overfitting the data.\n",
    "       ii. Guarding against bad attribute choices.\n",
    "      iii. Handling continuous valued attributes.\n",
    "       iv. Handling missing attribute values.\n",
    "        v. Handling attributes with differing costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ca87e",
   "metadata": {},
   "source": [
    "## 22. Briefly describe the random forest model.\n",
    "\n",
    "        The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
