{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28150796",
   "metadata": {},
   "source": [
    "## 1. Using a graph to illustrate slope and intercept, define basic linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26a15cc",
   "metadata": {},
   "source": [
    "![images](Slope-intercept-form_01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694096f0",
   "metadata": {},
   "source": [
    "## 2. In a graph, explain the terms rise, run, and slope.\n",
    "\n",
    "        a. Rise : Difference between two y-coordinates of two points\n",
    "        b. Run : Difference between two x-coordinates of two points\n",
    "        c. Slope : rise divided by run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa1ef9",
   "metadata": {},
   "source": [
    "![rise](rise-over-run-formula-1624864258.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c38b83",
   "metadata": {},
   "source": [
    "## 3. Use a graph to demonstrate slope, linear positive slope, and linear negative slope, as well as the different conditions that contribute to the slope.\n",
    "\n",
    "![images](slope-of-a-line-1638958953.png)\n",
    "\n",
    "Slope of a line purely depneds on the angle theta i.e. the angle betwee the x axis and the line,if that angle is less than 90,the slope is positive,negative, if else\n",
    "\n",
    "![images](IMG_Econ_01_004.png)\n",
    "![images](IMG_Econ_01_005.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487c23f",
   "metadata": {},
   "source": [
    "## 4. Use a graph to demonstrate curve linear negative slope and curve linear positive slope.\n",
    "\n",
    "If a curve slopes in positive direction,it's said to be a positive slope e.g. :\n",
    "\n",
    "![gif](Eight22.gif)  ![gif](Eight23.gif)\n",
    "\n",
    "If a curve slopes in negative direction,it's said to be a positive slope e.g. :\n",
    "\n",
    "![gif](Eight24.gif)  ![gif](Eight25.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d97a7",
   "metadata": {},
   "source": [
    "## 5. Use a graph to show the maximum and low points of curves.\n",
    "\n",
    "        To find the max,min of a curve,we differentiate it first and equate it to zero,secondly,we differentiate it again and check wether it is greater than or less than zero\n",
    "        \n",
    "![image](max-min-curve-26n6kwa.jpg)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fcbbe",
   "metadata": {},
   "source": [
    "## 6. Use the formulas for a and b to explain ordinary least squares.\n",
    "\n",
    "        This best line is the Least Squares Regression Line (abbreviated as LSRL). This is true where ˆy is the predicted y-value given x, a is the y intercept, b and is the slope. For every x-value, the Least Squares Regression Line makes a predicted y-value that is close to the observed y-value, but usually slightly off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc2e5e",
   "metadata": {},
   "source": [
    "## 7. Provide a step-by-step explanation of the OLS algorithm.\n",
    "\n",
    "        Ordinary Least Square Method :\n",
    "\n",
    "        i. Set a difference between dependent variable and its estimation:\n",
    "       ii. Square the difference:\n",
    "      iii. Take summation for all data.\n",
    "       iv. To get the parameters that make the sum of square difference become minimum, take partial derivative for each parameter and equate it with zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed715e9",
   "metadata": {},
   "source": [
    "## 8. What is the regression's standard error? To represent the same, make a graph.\n",
    "\n",
    "        The standard error of the regression (S), also known as the standard error of the estimate, represents the average distance that the observed values fall from the regression line. Conveniently, it tells you how wrong the regression model is on average using the units of the response variable.\n",
    "        \n",
    "![image](standardErrorRegression3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c7828",
   "metadata": {},
   "source": [
    "## 9. Provide an example of multiple linear regression.\n",
    "\n",
    "        Prediction of CO2 emission based on engine size and number of cylinders in a car.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4140315",
   "metadata": {},
   "source": [
    "## 10. Describe the regression analysis assumptions and the BLUE principle.\n",
    "        \n",
    "        i. There should be a linear and additive relationship between dependent (response) variable and independent (predictor) variable(s). A linear relationship suggests that a change in response Y due to one unit change in X¹ is constant, regardless of the value of X¹. An additive relationship suggests that the effect of X¹ on Y is independent of other variables.\n",
    "        \n",
    "       ii. There should be no correlation between the residual (error) terms. Absence of this phenomenon is known as Autocorrelation.\n",
    "       \n",
    "      iii. The independent variables should not be correlated. Absence of this phenomenon is known as multicollinearity.\n",
    "      \n",
    "       iv. The error terms must have constant variance. This phenomenon is known as homoskedasticity. The presence of non-constant variance is referred to heteroskedasticity.\n",
    "       \n",
    "        v. The error terms must be normally distributed. \n",
    "        \n",
    "        BLUE: is an acronym for the following: Best Linear Unbiased Estimator. In this context, the definition of “best” refers to the minimum variance or the narrowest sampling distribution.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b20ba",
   "metadata": {},
   "source": [
    "## 11. Describe two major issues with regression analysis.\n",
    "\n",
    "        i. Heteroskedasticity : Variance of error term is not constant\n",
    "       ii. Multicolinearity : Error terms are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0331c7d6",
   "metadata": {},
   "source": [
    "## 12. How can the linear regression model's accuracy be improved?\n",
    "\n",
    "        i. Add more data\n",
    "       ii. Treat missing values and outliers\n",
    "      iii. Feature engineering and feature selection\n",
    "       iv. Multiple Algorithms\n",
    "        v. Algorithm tuning\n",
    "       vi. Ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5d2dd",
   "metadata": {},
   "source": [
    "## 13. Using an example, describe the polynomial regression model in detail.\n",
    "\n",
    "        A polynomial regression model is the kind of regression analysis model in which the independent variable is related to the dependent variable in the nth degree polynomial.e.g. covid-19 spread is related to various factors\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be529f4",
   "metadata": {},
   "source": [
    "## 14. Provide a detailed explanation of logistic regression.\n",
    "\n",
    "        Logistic regression is a statistical analysis method used to predict a data value based on prior observations of a data set.Based on historical data about earlier outcomes involving the same input criteria, it then scores new cases on their probability of falling into a particular outcome category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e439d7",
   "metadata": {},
   "source": [
    "## 15. What are the logistic regression assumptions ?\n",
    "        \n",
    "    Basic assumptions that must be met for logistic regression include independence of errors, linearity in the logit for continuous variables, absence of multicollinearity, and lack of strongly influential outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf90ac2",
   "metadata": {},
   "source": [
    "## 16. Go through the details of maximum likelihood estimation ?\n",
    "        \n",
    "        Maximum likelihood estimation is a method that determines values for the parameters of a model. The parameter values\", are found such that they maximise the likelihood that the process described by the model produced the data that were\", actually observed.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
