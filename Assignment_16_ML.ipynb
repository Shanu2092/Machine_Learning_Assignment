{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e37a91",
   "metadata": {},
   "source": [
    "## 1. In a linear equation, what is the difference between a dependent variable and an independent variable?\n",
    "\n",
    "        A dependent variable is an entity whose value depends entirely on the independent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d243a9",
   "metadata": {},
   "source": [
    "## 2. What is the concept of simple linear regression? Give a specific example.\n",
    "\n",
    "        A simple linear regression relies on the concept that all the independent variables are linearly related to the dependent variables.e.g. a certain drug can be directly related to the blood pressure and the body temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694562e",
   "metadata": {},
   "source": [
    "## 3. In a linear regression, define the slope.\n",
    "\n",
    "         The slope of a regression line (b) represents the rate of change in y as x changes. Because y is dependent on x, the slope describes the predicted values of y given x. The slope must be calculated before the y-intercept when using a linear regression, as the intercept is calculated using the slope. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb66ce",
   "metadata": {},
   "source": [
    "## 4. Determine the graph's slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2).\n",
    "\n",
    "         Slope(m) of a line can be calculated using the formula \n",
    "                     \n",
    "                     m = (y2-y2)/(x2-x1)\n",
    "         \n",
    "         In this case,x1 = 3,y1 = 2,x2 = 2, y2 = 2\n",
    "         \n",
    "         hence,      m = (2-2)/(2-3) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009916c",
   "metadata": {},
   "source": [
    "## 5. In linear regression, what are the conditions for a positive slope?\n",
    "\n",
    "        Slope of a Linear Regression model is positive iff two variables are directly related i.e, if if one goes up,other variable goes up as well,and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c9858",
   "metadata": {},
   "source": [
    "## 6. In linear regression, what are the conditions for a negative slope?\n",
    "\n",
    "        If one of the two related variables goes down in the same magnitude as the other variable goes up,then the slope will be negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601afea",
   "metadata": {},
   "source": [
    "## 7. What is multiple linear regression and how does it work?\n",
    "\n",
    "        Multiple linear regression refers to a statistical technique that uses two or more independent variables to predict the outcome of a dependent variable. The technique enables analysts to determine the variation of the model and the relative contribution of each independent variable in the total variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494372b",
   "metadata": {},
   "source": [
    "## 8. In multiple linear regression, define the number of squares due to error.\n",
    "\n",
    "        The mean squared error (MSE) tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them. It's called the mean squared error as you're finding the average of a set of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a040a655",
   "metadata": {},
   "source": [
    "## 9. In multiple linear regression, define the number of squares due to regression.\n",
    "\n",
    "        Sum of squares is a statistical technique used in regression analysis to determine the dispersion of data points. In a regression analysis, the goal is to determine how well a data series can be fitted to a function that might help to explain how the data series was generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17938ca6",
   "metadata": {},
   "source": [
    "## 10. In a regression equation, what is multicollinearity?\n",
    "\n",
    "        Multicollinearity occurs when two or more independent variables are highly correlated with one another in a regression model. This means that an independent variable can be predicted from another independent variable in a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ed7e8",
   "metadata": {},
   "source": [
    "## 11. What is heteroskedasticity, and what does it mean?\n",
    "\n",
    "        heteroskedasticity (or heteroscedasticity) happens when the standard deviations of a predicted variable, monitored over different values of an independent variable or as related to prior time periods, are non-constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f277e7",
   "metadata": {},
   "source": [
    "12. Describe the concept of ridge regression.\n",
    "\n",
    "13. Describe the concept of lasso regression.\n",
    "\n",
    "14. What is polynomial regression and how does it work?\n",
    "\n",
    "15. Describe the basis function.\n",
    "\n",
    "16. Describe how logistic regression works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f740e48",
   "metadata": {},
   "source": [
    "## 12. Describe the concept of ridge regression.\n",
    "\n",
    "        Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity.By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors. It is hoped that the net effect will be to give estimates that are more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddaba6",
   "metadata": {},
   "source": [
    "## 13. Describe the concept of lasso regression.\n",
    "\n",
    "        Least Absolute Shrinkage and  Selection Operator Regression (LASSO Regression) is another regularized version of Linear Regression:just like Ridge Regression,it adds a regularization term to the cost functionn,but it uses the l1 norm of the weight vector instead of half the square of the l2 norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722dc83",
   "metadata": {},
   "source": [
    "## 14. What is polynomial regression and how does it work?\n",
    "\n",
    "        Polynomial Regression is a form of Linear regression known as a special case of Multiple linear regression which estimates the relationship as an nth degree polynomial. Polynomial Regression is sensitive to outliers so the presence of one or two outliers can also badly affect the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be3406",
   "metadata": {},
   "source": [
    "## 15. Describe the basis function.\n",
    "\n",
    "        This is a generalization of linear regression that essentially replaces each input with a function of the input. (A linear basis function model that uses the identity function is just linear regression.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5918c",
   "metadata": {},
   "source": [
    "## 16. Describe how logistic regression works.\n",
    "        \n",
    "        Logistic regression uses an equation as the representation, very much like linear regression. Input values (x) are combined linearly using weights or coefficient values (referred to as the Greek capital letter Beta) to predict an output value (y)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
